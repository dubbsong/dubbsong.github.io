---
layout: post
title: "거의 모든 인터넷의 역사"
categories: dev
tags: books
---

###### 정지훈 저

<br>

#### 서문

- 우리는 IT와 인터넷을 대부분 기술의 발달, 그로 인해 생산되는 금전적 이윤 등 '산업과 경제적인 관점'에서만 바라보는 것에 익숙해 있다.
- 중요한 것은 단순한 기술과 산업, 제품을 넘어서서 인터넷이 품고 있는 근본적인 의미를 이해하고, 새로운 미래를 향해 나아갈 수 있으면서 전 세계 지구촌 주민들과 공감할 수 있는 그런 철학과 가치를 함께 부여하는 것이다.

<br>

## CHAPTER 01 인간과 어우러지는 기계

- 인터넷과 웹이라는 것이 기술적인 분야 같지만, 실제로는 현대철학과 사회과학 및 정치와 법 제도, 그리고 글로벌 역학관계에 이르는 무수한 요소들이 결합되어 탄생한 것이다.
- 노버트 위너(Norbert Wiener)는 제자 클로드 섀넌(Claude Shannon)과 함께 전자 스위치 회로에서 통신으로 전달된 '정보'를 측정할 수 있는 가능성을 만드는 연구를 진행하였다. 1942년 이 정보 처리의 단위를 `binary digit`의 약자인 `비트(bit)`로 확정하였는데, 이들이 바로 디지털 시대의 원자인 비트를 탄생시킨 것이다.
- 일반 대중에게는 아인슈타인이 훨씬 유명하겠지만, 인터넷 역사에서는 폰 노이만(John von Neumann)이 훨씬 중요한 역할을 한 인물이다.
- 게임 이론은 원래 체스와 같은 게임에 숨어 있는 수학적 원리를 풀기 위해 고안되었다. 시장에서 물건을 사는 사람과 파는 사람의 교환 행위를 일종의 게임으로 보고, 교환이 이루어지는 메커니즘과 성립 조건, 교환 행위가 안정화되어 장기적 거래나 시장으로 발전하기 위해 필요한 조건 등을 알아내기만 하면 많은 이득을 얻을 수 있다는 점에 착안한 것이다.
- 원자폭탄과 관련된 다양한 모의실험을 위해서는 빠른 속도로 계산할 수 있는 계산기가 필요했는데, 이런 용도로 사용하기 위해 만들어진 것이 바로 컴퓨터 에니악(ENIAC)이다. 이것은 진공관으로 만들어진 세계 최초의 컴퓨터로서, 노이만의 자문을 받아 펜실베이니아 대학에서 제작하였다. 그런데 비트로 논리연산을 하기 위해 하드웨어 스위치를 연결한 것까지는 나쁘지 않았지만, 이 컴퓨터에 다른 일을 시키려면 전기회로를 모두 바꿔줘야 한다는 큰 문제점이 있었다. 이 문제를 해결하기 위해 노이만이 제안한 것이 '프로그램을 내장한 컴퓨터' 방식이다. 말하자면 중앙처리장치(CPU) 옆에 기억장치(memory)를 붙여서, 프로그램과 데이터를 기억장치에 저장해놓았다가 사람이 실행시키는 명령에 따라 작업을 차례로 불러내어 처리하는 것이다.
- 일설에 의하면 '폰 노이만 방식 컴퓨터' 개념의 본질적인 아이디어는, 영국의 앨런 튜링(Alan Turing)이 먼저 생각했다는 이야기도 있고, 노이만이 프린스턴 대학에서 이 아이디어를 훔쳤다는 이야기도 한동안 오르내렸다.
- 어찌 됐든 1949년 영국 케임브리지 대학에서 노이만의 개념을 도입한 에드삭(EDSAC) 컴퓨터를 개발하였고, 이는 최초의 프로그램 내장방식 컴퓨터로 인정받았다.
- 노버트 위너는 종래의 객관적인 실험을 바탕으로 하는 과학영역과는 전혀 다른 관점으로 접근하였다. 이후 윤리학과 인류의 미래에 대한 고민을 담아낸 비과학적인 개념, 그리고 네트워크와 통신 등에 의한 연결을 중시한 사이버네틱스를 구상하였다.
- 존 폰 노이만은 컴퓨터라는, 즉 대단히 빠른 연산을 할 수 있는 계산기를 창조하고, 수많은 데이터를 처리하고 프로그램을 내장하여 다양한 용도로 활용할 수 있는 길을 열었다.
- 미국 동부가 컴퓨터 개발의 거점이 될 수 있었던 것은 오대호 주변의 오하이오 주나 미시건 주가 19세기 후반부터 미국 공업의 중심지였기 때문이다. 특히 산업의 근간을 형성한 석유, 철강, 자동차 산업 등이 오대호 주변에서 번성했다. 또한 산업의 인프라를 형성하는 철도, 전력, 통신에 대해서도 동부에 투자가 집중되어 있다는 점도 빼놓을 수 없다.
- 트랜지스터는 윌리엄 쇼클리(William Bradford Shockley)라는 물리학자가 존 바딘(John Bardeen), 월터 하우저 브래튼(Walter HouserBrattain)과 공동으로 발명한 것으로, 이로 인해 그들은 1956년 노벨 물리학상을 수상하기도 했다.
- 진공관을 대체하는 트랜지스터는 실리콘을 소재로 하여 발명되었는데, 이는 21세기 디지털 세계를 여는 열쇠가 되었다.
- 반도체 회사의 급성장으로 인해 실리콘을 재료로 한 산업이 샌프란시스코 남쪽의 밸리 지역을 번성케 하면서 이 지역을 실리콘밸리라고 부르기 시작했다.
- 바네바 부시(Vannevar Bush)는 1946년에 발표한 메멕스(MEMEX, MEMory EXtender)라는 개념으로 유명한 인물이다. 인간이 여러 세대에 걸쳐 축적한 방대한 지식을 빠르게 검색하고 이용하게 되면 인류의 정신적 능력이 크게 발전할 것이라 생각했다. 따라서 인간이 생산한 정보와 지식을 정리하여 빠르게 검색할 수 있는 소형 컴퓨터의 시스템이 필요하다고 주장했는데, 그것이 바로 메멕스다. 메멕스는 개인용 컴퓨터와 웹을 탄생시킨 배경이 된다.
- 메멕스는 개인의 책과 기록물 모두를 저장함으로써 인간의 기억을 보완하기 위해 개발된 장치다.
- 실리콘밸리의 성장이 미래의 서부 산업에 매우 중요한 역할을 했다면, 인터넷과 관련된 네트워크 철학과 오늘날까지 면면히 이어지는 커뮤니티, 그리고 해커 중심 문화에는 미국 서부에서 뜨거운 바람을 일으켰던 대항문화(counterculture)가 그 뿌리로서 존재한다.
- 대항문화란 1960년대에 기성사회 주류문화에 대해 대안적 삶의 방식과 의미 체계를 제시한 사회운동을 일컫는다.
- 최첨단 네트워크를 운용하기 위해서는 강력한 컴퓨팅 파워가 필요했고, 이를 위해서 효율적인 컴퓨터 운영체제가 절실히 요구되었다. 이런 필요성에 의해 벨 연구소에서 개발한 운영체제가 바로 유닉스이다.
- 유닉스는 교육 및 연구기관에서 즐겨 사용되는 운영체제로서, 여러 명이 동시에 시간을 나누어 컴퓨터를 이용할 수 있도록 해준다.
- 오픈 소스 진영에서도 유닉스와 유사한 운영체제를 많이 만들게 되는데, 우리가 꼭 알아야 할 중요한 운영체제가 바로 리눅스(Linux)이다.
- 리눅스는 소프트웨어 산업에 있어 무수한 영향력을 행사한 기념비적인 소프트웨어이다.
- 오늘날 아이폰과 함께 전 세계를 호령하는 모바일 운영체제인 안드로이드를 비롯하여, 삼성전자가 주도하는 타이젠(Tizen), 그리고 최그 새로운 대안으로 떠오르는 양대 산맥인 우분투(Ubuntu)와 모질라의 파이어폭스(Firefox) 운영체제도 모두 리눅스를 조상으로 하여 파생된 것이다.
- 해커 정신(Hacker Way)이란 백 마디 말과 계획을 세우기보다, 바로 실행해보고 혁신하는 문화이다. 실패를 하더라도 빨리 실패하고, 거기에서 필요한 교훈을 얻어야 더 나은 서비스와 경험을 고객들에게 제공할 수 있다는 얘기다.
- 매사에 세밀하게 계획을 세워 실행하는 사람이 '플래너(Planner)'라면, 이와 반대로 즐거움에 이끌려 임의적으로 새로운 혁신을 하거나 발명하는 사람을 '해커(Hacker)'라 불렀다.
- 제록스파크 연구소의 해커들은 PDP-7 컴퓨터를 이용해서 우주 전쟁을 테마로 한 텍스트 게임인 스페이스워 게임을 개발하고 즐기기 시작했다. 여러 사람이 게임을 즐기기 위해서는 네트워크가 필요했고, 이때 이용한 네트워크가 오늘날 인터넷의 효시인 `아파넷`이 되었다.
- 제록스파크에서 스페이스워를 즐겼던 해커들이 이용한 아파넷은 오늘날 인터넷의 전신이 된 컴퓨터 네트워크이다.
- 미국 전역에 있는 유수의 연구기관들의 연구 역량을 극대화하기 위해서 정보를 교환하는 인프라의 중요성이 대두되었다. 사실상 냉전 당시에 가장 위협적인 시나리오였던 핵 공격이 있을 경우 통신 기능의 파괴를 막기 위해서는 무엇보다도 새로운 형태의 네트워크 기술이 요구되었다. 이런 목적을 달성하기 위해서는 기존의 전화망과 같이 각각의 지점을 직선으로 연결하는 형태보다는, 효율성은 다소 떨어지더라도 우회를 통해서 연결이 끊어지지 않도록 하는 분산형 네트워크 구조가 필요했다. 그리고 네트워크의 가용성을 높이기 위해서 데이터를 잘게 자르고, 복수의 경로를 통해서 보내더라도 수신 측에서 이를 재구성할 수 있도록 패킷(packet)을 활용할 수 있게 설계하였다. 또한 네트워크 일부가 파손되어도 쉽게 복구할 수 있도록 네트워크 간의 통신 규칙인 프로토콜을 정했다. 프로토콜만 준수하면 누구나 손쉽게 새로운 네트워크에 접속할 수 있도록 하기 위해서이다.
- 네트워크 망과 관련한 프로토콜인 TCP/IP(Transmission Control Protocol/Internet Protocol)는 빈튼 서프(Vinton Cerf)와 밥 칸(Bob Khan)이 고안한 것으로, 오늘날 인터넷의 근간을 이루는 프로토콜이다. 인터넷 상에 있는 컴퓨터끼리 데이터를 주고 받는 방법을 정의하고 있다고 보면 된다.
- 인터넷에서 TCP/IP는 가장 핵심적인 기능을 담당하는 인프라와도 같은 것이다.
- 리눅스의 기저에는 모든 개발자들이 뛰어난 코드를 작성하지 못했다 하더라도 여럿이 함께 코드를 검토하고 개발한다면 결국 위대한 코드가 나타날 수 있다는 믿음이 깔려 있다.

<br>

## CHAPTER 02 각각의 네트워크를 한 곳으로

- 인터넷의 역사를 짚어보는 데 있어 1970~1980년대의 기술적 성과를 언급하지 않은 채, 개인의 업적이나 기업의 흥망만을 살펴보는 것은 아무런 의미가 없다.
- 여러 네트워크 기술과 구조를 포괄해야 했기 때문에 오픈 아키텍처를 통해서 미래로의 확장성을 우선 확보해야 했다. 다시 말해 어느 한쪽이 송신하고 다른 한쪽이 수신하는 역할 분담식의 시나리오보다는, 각 네트워크의 말단이 독립적인 역할을 수행하면서 각자의 소통이 가능한 P2P(Peer-to-Peer, 각각의 말단이 대등하게 주고받는 형태) 시나리오를 지원하는 것이 중요했다.
- 오픈 아키텍처 네트워크에서는 각각의 독립적인 네트워크가 자신들만의 인터페이스를 통해 서비스를 사용자들에게 제공하고, 이들 간의 네트워크를 다시 구성할 수 있어야 한다. 그리고 바로 여기에는 인터넷 서비스를 제공하는 인터넷 서비스 제공자(ISP, Internet Service Provider) 개념이 나오게 된다.
- 오픈 아키텍처 네트워크 개념이 실질적으로 성공하기 위해서는 신뢰성 있는 네트워크 단말 사이의 통신 프로토콜을 만드는 것이 가장 중요했다. 데이터 중심의 통신을 하다 보면 자연스럽게 다양한 형태의 전파나 전기 간섭, 방해 등이 있을 수 있기 때문이다. 이동하는 환경을 가정할 경우에도 터널을 지나거나, 통신 인프라가 열악한 산간지역 등에서 통신이 끊어지는 것 등에 대해서도 대비해야 한다.
- 오픈 아키텍처 네트워크를 위해서는 통신 프로토콜의 형태로 재정의할 필요가 있었다. 각각의 네트워크는 독립적으로 유지되면서도, 네트워크 간의 네트워크인 인터넷에 접속될 때 특별한 변화나 조작이 없어야 했다. 그리고 데이터 덩어리인 패킷이 목적지에 도달하지 않을 때 멈춰버리기보다는, 시간이 지나서 원래 발신한 곳에서 재전송이 일어나야 했으며, 네트워크들 사이를 연결하는 보편적인 블랙박스 같은 것이 필요했다. 이렇게 네트워크 사이를 연결하는 장치가 오늘날 게이트웨이(gateway)와 라우터(router)라 불리는 것들이다.
- 또 하나의 중요한 이슈는 주소와 관련된 것이다. 사라지는 패킷을 처리하고, 재전송을 원활하게 하기 위해서는 데이터 패킷에 어디로 어떻게 가는 것이 좋은지에 대한 정보를 담고 있어야 했다. 게이트웨이가 패킷을 벗겨서 네트워크가 흘러가는 길의 정보(루트)와 인터페이스 처리, 필요하다면 데이터 패킷을 잘게 자르는 등의 정보를 해석할 수 있어야 하는데, 이런 정보를 IP(Internet Protocol) 헤더에 담도록 했다.
- 또한 에러 등의 이유로 순서를 가리지 않고 들어오는 데이터 패킷을 나중에 재조합해야 했으며, 전송이 잘 안 됐을 거라 여기고 다시 또 전송하는 등 데이터 중복 처리에 대비해야 하므로 체크섬을 계산하도록 했다. 그리고 호스트 사이의 흐름도 제어하고, 전체적인 시스템의 완결성을 위해서는 주소체계도 필요했다.
- 밥 칸의 뛰어난 아키텍처 개념에, 빈튼 서프의 NCP 및 운영체제에 대한 지식이 합쳐지자 마침내 놀라운 성과가 나왔다. 바로 오늘날 인터넷 기기들의 소통언어라 할 수 있는 TCP/IP 프로토콜이 완성된 것이다.
- TCP/IP 프로토콜과는 별도로 제록스파크 연구소에서는 `이더넷(Eternet)`이라는 새로운 네트워크 기술이 연구되고 있었다. 이더넷이 널리 보급되면서 LAN(Local Area Network)의 시대가 열렸다.
- 인터넷과 관련한 프로토콜을 디자인한 빈튼 서프나 밥 칸은 금방 활성화될 것이라고는 상상하지 못해서, 가능한 주소의 수가 32비트 정도면 충분하다고 여겼다. 그래서 현재와 같은 4바이트의 32비트 IP 주소체계가 세워지게 된 것이다. 이제는 주소가 완전히 포화되어 IPv6라고 불리는 128비트 주소체계로 전환되고 있다 하니, 기술과 미래를 예측한다는 것이 얼마나 어려운지를 상징적으로 보여주는 일이 아닌가 싶다.
- 인터넷의 근간을 이루는 TCP/IP 프로토콜을 개발한 빈튼 서프는 밥 칸과 함께 '인터넷의 아버지'라고도 불린다.
- 많은 사람들이 어떤 서비스를 적극적으로 활용하게 되면 그 가치가 크게 늘어난다는 것을 이제는 아무도 의심하지 않는다.
- 성능 좋은 메인프레임 컴퓨터를 아파넷에 연결된 여러 터미널 기기를 통해 시간을 분할해서 사용한다면, 각각의 기관이나 개인들이 모두 이렇게 비싼 컴퓨터를 구매하지 않고도 경제적으로 이용할 수 있다. 이런 목적에서 개발된 것이 바로 텔넷(TELNET)과 FTP(File Transfer Protocol, 파일 전송 프로토콜)이다. 이것들은 아파넷과 같이 커다란 네트워크를 효과적으로 이용하는 데 필요한 기술로 개발된 것이다.
- 텔넷은 원격지에 있는 호스트 컴퓨터를 이용하기 위해 원격지에서 로그인 기능을 제공하는 프로토콜이다. 이를 리모트 로그인(remote login)이라고 하는데, 초창기 인터넷에 있어서 가장 중요한 역할을 담당했다.
- 텔넷과 PC, 모뎀의 보급은 향후 전화 접속 서비스와 PC 통신을 탄생시키기도 했다. 그러나 1990년대에 들어서서 인터넷 사용자와 데이터의 양이 크게 늘어나면서 서버를 해킹하는 사람들에 대한 보안 때문에 문제시되었다. 그 후 여러 차례 변형을 거쳣지만, 최근에는 거의 이용하지 않는다.
- 네트워크에서 자원을 효과적으로 공유하는 데 또 한 가지 반드시 필요한 기능이 있었으니, 바로 파일을 주고 받는 일이었다.
- 네트워크에 연결되는 호스트의 수가 많아지면서 주소를 4바이트의 수(예를 들어 108.92.35.4)로 기록하고 관리하는 것이 어려워진 점이다. 사람들이 쉽게 네트워크 호스트에 접근하도록 만들기 위해서는 이름을 붙이되, 이름으로 네트워크에 접근을 시도할 때 원래 주어진 숫자로 만들어진 주소로 변경하는 서비스의 필요성이 제기되었다. 이런 문제를 해결하기 위해 탄생한 것이 바로 DNS(Domain Name System)이다. 이름으로 이루어진 주소를 가진 분산된 서버가 네트워크 상에 여럿 존재하면 계층화된 호스트의 이름(예를 들어 www.google.com)을 숫자로 이루어진 인터넷 주소로 변경해주도록 한 것이다.
- 우리가 PC에서 네트워크 주소를 이름으로 입력하면, 이런 서버를 가진 곳에 먼저 접근해서 입력한 이름을 숫자로 된 인터넷 주소로 변경하고, 결국 해당 주소로 연결해주는 것이다. 이런 서버를 DNS 서버라고 한다. 만약 숫자로 된 주소를 모두 기억하고 있다면, DNS가 제대로 작동하지 않더라도 각각의 웹사이트 호스트에 접근이 가능하다.
- DNS 구조에는 또 다른 장점도 있다. 이름으로 접근하기 때문에, 만약의 경우 웹사이트 등의 호스트를 다양한 이유로 확장하거나 변경해야 하는 경우가 발생하더라도 DNS에 등록만 변경하면 많은 사람들이 주소가 바뀌었다는 것을 몰라도 된다.
- DNS가 잘 동작하기 위해서는 이름을 등록하고 관리하는 체계가 필요했다. 이런 일을 위해 설립된 것이 바로 ICANN이다.
- 과연 인터넷은 국가의 관리 체계 아래로 들어갈 수 있는 것일까?
- 이메일은 인터넷 확산에 가장 핵심적인 역할을 했다. 전자 메일(electronic mail)의 약자인 이메일의 개념은 굉장히 오랫동안 많은 사람들이 꿈꾸어왔던 기능이었다. 당시의 컴퓨터는 대부분 호스트의 역할을 하였으므로, 컴퓨터 호스트의 주소와 받는 사람의 아이디를 분리하는 구분자로서 `@`를 처음으로 사용하게 되었다.
- 오늘날의 인터넷은 단지 기술이 아니라 많은 사람들의 생각을 퍼뜨리고 연계시키기 위한 고도의 정치적 활동을 통해서 만들어진 것이다.
- 슈퍼컴퓨터는 주로 물리학에서 복잡한 연산을 처리하거나, 날시 예측, 석유나 가스 탐사, 화학에서의 분자모델링, 물리 시뮬레이션과 우주항공 분야, 핵무기 연구 등과 같이 국가적으로 중대하게 생각할 수 있는 기초과학 분야에서 강력한 성능을 발휘하였다.
- 1995년 10월 24일, 미국 연방 네트워킹위원회(FNC)는 만장일치로 인터넷이라는 용어에 대한 정의를 통과시켰다.
  1. 인터넷은 다음과 같은 특징을 가진 글로벌 정보 시스템을 일컫는다.
  2. 인터넷 프로토콜(IP, Internet Protocol) 또는 IP의 확장이나 후속 프로토콜에 기반을 둔 글로벌하게 유일한 주소 공간에 의해 논리적으로 연결되어 있다.
  3. TCP/IP 프로토콜 또는 이의 확장이나 후속 프로토콜, 그리고 다른 IP와 호환되는 프로토콜을 이용한 통신을 지원할 수 있어야 한다.
  4. 위에 언급한 인프라 구조나 통신 계층 위의 공공 또는 사적으로 고수준의 서비스를 제공하거나 사용, 접근이 가능하다.

<br>

## CHAPTER 03 웹의 시대가 열리다

- 인터넷에 담겨 있는 정보의 양과, 사용자들이 최소한의 시간을 들여 원하는 내용들을 찾아볼 수 있는 것은 모두 하이퍼텍스트(Hypertext) 기능 때문이다.
- 팀 버너스 리(Tim Berners Lee)는 하이퍼텍스트의 형태로 인터넷을 통해 정보를 주고 받는 기술을 연구하였다. 링크를 클릭하고 이로 인해서 새로운 정보를 탐색하는 개념인데, 지금은 익숙하지만 처음 등장한 당시로서는 획기적인 UX(User Experience, 사용자 경험)였다.
- 최초의 웹 서버는 스티브 잡스가 만든 넥스트(NeXT) 컴퓨터가 이용되었는데, 팀 버너스 리와 로버트 까유에 따르면 넥스트 컴퓨터의 하이퍼텍스트를 쉽게 구현할 수 있는 멋진 객체 지향 컴퓨팅 환경이 웹의 구현에 결정적인 역할을 했다고 한다. 그런 측면에서 보면 스티브 잡스 역시 웹의 탄생에 커다란 기여를 한 셈이다.
- 처음 만들어진 웹사이트에는 하이퍼텍스트가 무엇이고, 어떻게 웹페이지를 만드는지에 대한 기술적인 설명, 그리고 FTP를 통해 소스코드를 다운로드 받을 수 있는 링크까지 걸려 있었다. 이 웹사이트는 웹과 관련한 표준을 만들고 운영하는 W3C(World Wide Consortium)에 의해 보존이 되고 있다.
- 기술과 산업 부문은 혼자만 잘한다고 앞서가는 것이 아니다. 수많은 사람들과 함께 자유롭고 창의적인 노력을 나눔으로써 비로소 발전할 수 있다.
- 마크 앤드리센(Marc Andreessen)은 웹과 같은 좋은 기술이 보통 사람도 쉽게 이용할 수 있는 프로그램으로 보급되어야 한다고 늘 생각해왔다. 특히 웹에 있는 다양한 과학 정보를 일반인들이 쉽게 접근해서 볼 수 있도록 하는 브라우저가 그 핵심이라고 생각했다. 1993년, 오늘날 웹 브라우저 역사에 길이 남는 범용 브라우저인 모자이크(Mosaic)를 완성하게 된다. 마우스만으로 인터넷을 브라우징할 수 있는 클릭앤포인트(Click and Point) 방식을 처음으로 구현한 모자이크는 인터넷이 진정한 정보의 바다가 될 수 있음을 보여주는 데 성공했다. 모자이크는 당시 윈도우, 매킨토시, 유닉스를 모두 지원한 최초의 브라우저였다.
- JavaScript는 넷스케이프의 브렌단 아이크(BrendanEich)에 의해 개발되었다. 브렌단 아이크는 모자이크를 잡기 위해서는 웹에 프로그래밍의 힘을 부여할 수 있는 무언가가 필요하다고 생각했다. 그래서 웹 디자이너들이 HTML을 이용해서 홈페이지를 만들 때 웹페이지에 직접 삽입 가능한 간단한 프로그래밍을 고안하기로 했다. 당시 가장 유명한 프로그래밍 언어는 C/C++이었지만, 자바도 많은 사람들에게 사랑받고 있었다. 그렇기에 복잡한 언어를 새로 고안하기보다는 자바의 문법을 일부 빌려와 스크립트 언어를 정의하기 시작했다. 이것이 바로 JavaScript인 것이다.
- JavaScript를 디자인하면서 가장 중요하게 생각한 것은, 쉽게 카피 및 복사를 하여 기능을 그대로 옮길 수 있도록 하는 점이었다. 특히 디자이너들이 편리하게 활용할 수 있는지의 여부가 가장 중시되었다.
- 1995년 3월 1일 정식으로 회사를 창업한 Yahoo는 정보를 찾는 사람들의 첫 기착지 역할을 톡톡히 해내면서, 글자 그대로 인터넷으로 들어가기 위한 포털(portal, 문)의 역할을 하기 시작했다.
- 아마존은 규모가 커지면서 고객에게 보다 나은 서비스를 제공할 수 있었는데, 특히 개인정보와 신용카드의 정보를 가진 아마존을 고객들이 신뢰하도록 하는 데 역량을 집중했다. 얼마 지나지 않아 어느 곳보다 안전한 전자상거래 플랫폼을 제공하는 데 성공했다. 이를 해결하기 위해 아마존이 채택한 기술이 캘리포니아의 수학자 세 명에게 제시한 PKI(Public Key Infrastructure, 공개 키 기반 구조, 암호화와 보완과 관련한 중요한 기반 기술)이다.
- 광고 시장을 단순화해서 보면 크게 세 가지 플레이어들이 존재한다. 광고를 싣고자 돈을 지불하는 광고주, 그리고 광고를 실어서 이익을 내는 미디어, 마지막으로 광고를 보는 소비자이다.

<br>

## CHAPTER 04 인터넷은 기술인가, 철학인가?

- 블로그는 웹로그(Weblog)를 달리 부른 것으로, 개인에게 최적화된 홈페이지로 댓글 관리와 일정, 그리고 트랙백과 같이 블로그를 연결할 수 있는 방법과 구독 등의 기술들이 들어간 것이다.
- "This thing is huge, and we're going to kick ass at it."
- "This might be a thing if we pull this off."
- 아마존의 아마존 웹 서비스(AWS) 전략이 훌륭한 것은, 덩치가 큰 운영체계적 요소를 한꺼번에 개발해서 릴리즈를 하는 것이 아니라, 철저히 수요가 있는 서비스 스택부터 하나씩 모듈화해서 내놓는 점에 있다. 과도한 리소스를 사용하지 않으면서 필요한 조각들을 순차적으로 차세대 웹 플랫폼으로 내놓고, 이들이 지속적으로 사용될 수 있는 환경을 조성한 것이다.
- 


































